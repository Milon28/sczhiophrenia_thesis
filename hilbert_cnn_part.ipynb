{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50cc4b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (2.1.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (3.10.3)\n",
      "Requirement already satisfied: seaborn in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (1.6.1)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (2.19.0)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\python311\\lib\\site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (1.72.1)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\milon\\appdata\\roaming\\python\\python311\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "   ---------------------------------------- 0.0/39.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/39.5 MB 660.6 kB/s eta 0:01:00\n",
      "   ---------------------------------------- 0.1/39.5 MB 975.2 kB/s eta 0:00:41\n",
      "   ---------------------------------------- 0.2/39.5 MB 1.5 MB/s eta 0:00:27\n",
      "   ---------------------------------------- 0.4/39.5 MB 2.4 MB/s eta 0:00:17\n",
      "    --------------------------------------- 0.8/39.5 MB 3.8 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 1.4/39.5 MB 5.0 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 1.4/39.5 MB 5.3 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 1.7/39.5 MB 5.0 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 2.0/39.5 MB 5.2 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 2.0/39.5 MB 5.2 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 2.1/39.5 MB 4.6 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 3.1/39.5 MB 5.9 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 3.3/39.5 MB 5.8 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 3.7/39.5 MB 5.9 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 3.7/39.5 MB 5.9 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 4.8/39.5 MB 6.5 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 5.2/39.5 MB 6.7 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 5.7/39.5 MB 6.9 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 6.2/39.5 MB 7.1 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 6.7/39.5 MB 7.2 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 7.1/39.5 MB 7.4 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 7.6/39.5 MB 7.5 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 8.1/39.5 MB 7.6 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 8.6/39.5 MB 7.7 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 9.1/39.5 MB 7.9 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 9.6/39.5 MB 8.0 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 10.1/39.5 MB 8.1 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 10.5/39.5 MB 9.0 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 11.0/39.5 MB 9.1 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 11.5/39.5 MB 9.1 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 12.0/39.5 MB 9.8 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 12.6/39.5 MB 10.7 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 13.1/39.5 MB 10.2 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 13.6/39.5 MB 10.4 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 14.1/39.5 MB 11.1 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 14.6/39.5 MB 10.7 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 15.1/39.5 MB 10.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 15.6/39.5 MB 10.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 16.1/39.5 MB 10.7 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 16.6/39.5 MB 10.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 17.1/39.5 MB 10.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 17.7/39.5 MB 10.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 18.2/39.5 MB 10.9 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 18.7/39.5 MB 10.9 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 19.3/39.5 MB 10.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 19.8/39.5 MB 10.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 20.3/39.5 MB 11.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 20.8/39.5 MB 11.1 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 21.3/39.5 MB 11.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 21.9/39.5 MB 11.1 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 22.4/39.5 MB 11.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 22.9/39.5 MB 11.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 23.5/39.5 MB 11.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 24.0/39.5 MB 11.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 24.5/39.5 MB 11.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 25.0/39.5 MB 11.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 25.6/39.5 MB 11.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 26.1/39.5 MB 11.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 26.6/39.5 MB 11.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 27.2/39.5 MB 11.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 27.6/39.5 MB 11.5 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 28.2/39.5 MB 11.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 28.7/39.5 MB 11.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 29.3/39.5 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 29.8/39.5 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 30.3/39.5 MB 11.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 30.8/39.5 MB 11.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 31.3/39.5 MB 11.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 31.9/39.5 MB 11.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 32.4/39.5 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 33.0/39.5 MB 11.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 33.5/39.5 MB 11.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.8/39.5 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.9/39.5 MB 10.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.9/39.5 MB 11.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 35.2/39.5 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 35.6/39.5 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 36.0/39.5 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 36.4/39.5 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.8/39.5 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 37.2/39.5 MB 10.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 37.6/39.5 MB 10.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 38.1/39.5 MB 10.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 38.5/39.5 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.9/39.5 MB 9.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.5 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.5/39.5 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.5/39.5 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.5/39.5 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.5/39.5 MB 8.5 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy matplotlib seaborn scikit-learn tensorflow opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5e2c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "import cv2\n",
    "from collections import Counter\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e295d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n",
      "TensorFlow version: 2.19.0\n",
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61ecbda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Loading schizophrenia images...\n",
      "Found 5146 schizophrenia images\n",
      "Processing schizophrenia image 1/5146\n",
      "Processing schizophrenia image 1001/5146\n",
      "Processing schizophrenia image 2001/5146\n",
      "Processing schizophrenia image 3001/5146\n",
      "Processing schizophrenia image 4001/5146\n",
      "Processing schizophrenia image 5001/5146\n",
      "Loaded 5146 schizophrenia images\n",
      "Loading healthy images...\n",
      "Found 4235 healthy images\n",
      "Processing healthy image 1/4235\n",
      "Processing healthy image 1001/4235\n",
      "Processing healthy image 2001/4235\n",
      "Processing healthy image 3001/4235\n",
      "Processing healthy image 4001/4235\n",
      "Loaded 4235 healthy images\n",
      "\n",
      "Data loading complete!\n",
      "Total images loaded: 9381\n",
      "Schizophrenia samples: 5146\n",
      "Healthy samples: 4235\n",
      "Image shape: (9381, 224, 224, 3)\n",
      "Results directory created!\n"
     ]
    }
   ],
   "source": [
    "# UPDATE THESE PATHS TO YOUR ACTUAL DATA FOLDERS\n",
    "SCHIZOPHRENIA_PATH = \"D:/Milon2/HHT/S\"  # Replace with your actual path\n",
    "HEALTHY_PATH = \"D:/Milon2/HHT/H\"              # Replace with your actual path\n",
    "\n",
    "# Image settings\n",
    "IMG_SIZE = (224, 224)  # Adjust based on your image size\n",
    "\n",
    "def load_and_preprocess_data(schizophrenia_path, healthy_path, img_size):\n",
    "    \"\"\"Load and preprocess HHT plot images\"\"\"\n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # Load schizophrenia images (label: 1)\n",
    "    print(\"Loading schizophrenia images...\")\n",
    "    schizo_files = glob.glob(os.path.join(schizophrenia_path, \"*.png\"))\n",
    "    print(f\"Found {len(schizo_files)} schizophrenia images\")\n",
    "    \n",
    "    for i, file_path in enumerate(schizo_files):\n",
    "        if i % 1000 == 0:  # Progress indicator\n",
    "            print(f\"Processing schizophrenia image {i+1}/{len(schizo_files)}\")\n",
    "        try:\n",
    "            img = load_img(file_path, target_size=img_size)\n",
    "            img_array = img_to_array(img) / 255.0  # Normalize to [0,1]\n",
    "            X.append(img_array)\n",
    "            y.append(1)  # Schizophrenia\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "    \n",
    "    print(f\"Loaded {len([i for i in y if i == 1])} schizophrenia images\")\n",
    "    \n",
    "    # Load healthy images (label: 0)\n",
    "    print(\"Loading healthy images...\")\n",
    "    healthy_files = glob.glob(os.path.join(healthy_path, \"*.png\"))\n",
    "    print(f\"Found {len(healthy_files)} healthy images\")\n",
    "    \n",
    "    for i, file_path in enumerate(healthy_files):\n",
    "        if i % 1000 == 0:  # Progress indicator\n",
    "            print(f\"Processing healthy image {i+1}/{len(healthy_files)}\")\n",
    "        try:\n",
    "            img = load_img(file_path, target_size=img_size)\n",
    "            img_array = img_to_array(img) / 255.0  # Normalize to [0,1]\n",
    "            X.append(img_array)\n",
    "            y.append(0)  # Healthy\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "    \n",
    "    print(f\"Loaded {len([i for i in y if i == 0])} healthy images\")\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    print(f\"\\nData loading complete!\")\n",
    "    print(f\"Total images loaded: {len(X)}\")\n",
    "    print(f\"Schizophrenia samples: {np.sum(y == 1)}\")\n",
    "    print(f\"Healthy samples: {np.sum(y == 0)}\")\n",
    "    print(f\"Image shape: {X.shape}\")\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Load the data (MAKE SURE TO UPDATE PATHS ABOVE!)\n",
    "X, y = load_and_preprocess_data(SCHIZOPHRENIA_PATH, HEALTHY_PATH, IMG_SIZE)\n",
    "\n",
    "# Create results directory\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "print(\"Results directory created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d092de15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model creation...\n",
      "Model created successfully!\n",
      "\n",
      "Model Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36864</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">18,874,880</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36864\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │    \u001b[38;5;34m18,874,880\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,396,801</span> (73.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,396,801\u001b[0m (73.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,395,841</span> (73.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,395,841\u001b[0m (73.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing data augmentation...\n",
      "Data augmentation generator created successfully!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "def create_cnn_model(img_size):\n",
    "    \"\"\"Create CNN architecture for EEG classification\"\"\"\n",
    "    model = Sequential([\n",
    "        # Input layer (fixes the warning)\n",
    "        Input(shape=(*img_size, 3)),\n",
    "        \n",
    "        # First Conv Block\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Second Conv Block\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Third Conv Block\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Fourth Conv Block\n",
    "        Conv2D(256, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2, 2),\n",
    "        \n",
    "        # Flatten and Dense layers\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_data_augmentation():\n",
    "    \"\"\"Create data augmentation generator\"\"\"\n",
    "    return ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        zoom_range=0.1,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "# Test model creation\n",
    "print(\"Testing model creation...\")\n",
    "test_model = create_cnn_model(IMG_SIZE)\n",
    "print(\"Model created successfully!\")\n",
    "print(\"\\nModel Summary:\")\n",
    "test_model.summary()\n",
    "\n",
    "# Test data augmentation\n",
    "print(\"\\nTesting data augmentation...\")\n",
    "datagen = create_data_augmentation()\n",
    "print(\"Data augmentation generator created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de3b7fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up 3-fold cross validation...\n",
      "\n",
      "Fold distribution preview:\n",
      "Fold 1:\n",
      "  Training: 6254 samples (Schizo: 3430, Healthy: 2824)\n",
      "  Validation: 3127 samples (Schizo: 1716, Healthy: 1411)\n",
      "Fold 2:\n",
      "  Training: 6254 samples (Schizo: 3431, Healthy: 2823)\n",
      "  Validation: 3127 samples (Schizo: 1715, Healthy: 1412)\n",
      "Fold 3:\n",
      "  Training: 6254 samples (Schizo: 3431, Healthy: 2823)\n",
      "  Validation: 3127 samples (Schizo: 1715, Healthy: 1412)\n",
      "\n",
      "Cross-validation setup complete!\n",
      "Ready to train 3 models with 50 epochs each.\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation parameters\n",
    "N_SPLITS = 3\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Initialize variables for storing results\n",
    "fold_results = []\n",
    "fold_accuracies = []\n",
    "best_accuracy = 0\n",
    "best_model_path = \"best_eeg_cnn_model.h5\"\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "print(f\"Setting up {N_SPLITS}-fold cross validation...\")\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "# Show the data distribution for each fold\n",
    "print(\"\\nFold distribution preview:\")\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    train_schizo = np.sum(y[train_idx])\n",
    "    train_healthy = len(train_idx) - train_schizo\n",
    "    val_schizo = np.sum(y[val_idx])\n",
    "    val_healthy = len(val_idx) - val_schizo\n",
    "    \n",
    "    print(f\"Fold {fold+1}:\")\n",
    "    print(f\"  Training: {len(train_idx)} samples (Schizo: {train_schizo}, Healthy: {train_healthy})\")\n",
    "    print(f\"  Validation: {len(val_idx)} samples (Schizo: {val_schizo}, Healthy: {val_healthy})\")\n",
    "\n",
    "print(f\"\\nCross-validation setup complete!\")\n",
    "print(f\"Ready to train {N_SPLITS} models with {EPOCHS} epochs each.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b2a184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TRAINING FOLD 1/3\n",
      "==================================================\n",
      "Training samples: 6254 (Schizo: 3430, Healthy: 2824)\n",
      "Validation samples: 3127 (Schizo: 1716, Healthy: 1411)\n",
      "Starting training for fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Milon\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5111 - loss: 4.7669\n",
      "Epoch 1: val_accuracy improved from -inf to 0.55037, saving model to results/fold_1_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 1s/step - accuracy: 0.5112 - loss: 4.7567 - val_accuracy: 0.5504 - val_loss: 0.7251 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m  1/195\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:26\u001b[0m 1s/step - accuracy: 0.5938 - loss: 0.6906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Milon\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_accuracy did not improve from 0.55037\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 97ms/step - accuracy: 0.5938 - loss: 0.6906 - val_accuracy: 0.5497 - val_loss: 0.7284 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5495 - loss: 0.6923\n",
      "Epoch 3: val_accuracy did not improve from 0.55037\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 1s/step - accuracy: 0.5494 - loss: 0.6923 - val_accuracy: 0.4579 - val_loss: 0.7986 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m  1/195\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:35\u001b[0m 1s/step - accuracy: 0.5000 - loss: 0.6955\n",
      "Epoch 4: val_accuracy did not improve from 0.55037\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 111ms/step - accuracy: 0.5000 - loss: 0.6955 - val_accuracy: 0.4583 - val_loss: 0.7962 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5481 - loss: 0.6898\n",
      "Epoch 5: val_accuracy did not improve from 0.55037\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 1s/step - accuracy: 0.5481 - loss: 0.6898 - val_accuracy: 0.5488 - val_loss: 0.6885 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m  1/195\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:57\u001b[0m 1s/step - accuracy: 0.5312 - loss: 0.6904\n",
      "Epoch 6: val_accuracy did not improve from 0.55037\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 100ms/step - accuracy: 0.5312 - loss: 0.6904 - val_accuracy: 0.5488 - val_loss: 0.6885 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5530 - loss: 0.6880\n",
      "Epoch 7: val_accuracy did not improve from 0.55037\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 1s/step - accuracy: 0.5530 - loss: 0.6880 - val_accuracy: 0.5488 - val_loss: 0.6884 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m  1/195\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:29\u001b[0m 1s/step - accuracy: 0.5000 - loss: 0.6965\n",
      "Epoch 8: val_accuracy did not improve from 0.55037\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 95ms/step - accuracy: 0.5000 - loss: 0.6965 - val_accuracy: 0.5488 - val_loss: 0.6884 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5500 - loss: 0.6889\n",
      "Epoch 9: val_accuracy did not improve from 0.55037\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 1s/step - accuracy: 0.5500 - loss: 0.6889 - val_accuracy: 0.5481 - val_loss: 0.6885 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m  1/195\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:20\u001b[0m 1s/step - accuracy: 0.4375 - loss: 0.7087\n",
      "Epoch 10: val_accuracy did not improve from 0.55037\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 94ms/step - accuracy: 0.4375 - loss: 0.7087 - val_accuracy: 0.5481 - val_loss: 0.6885 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5527 - loss: 0.6880\n",
      "Epoch 11: val_accuracy did not improve from 0.55037\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 1s/step - accuracy: 0.5526 - loss: 0.6880 - val_accuracy: 0.5488 - val_loss: 0.6884 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m  1/195\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:31\u001b[0m 1s/step - accuracy: 0.7500 - loss: 0.6497\n",
      "Epoch 12: val_accuracy did not improve from 0.55037\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 97ms/step - accuracy: 0.7500 - loss: 0.6497 - val_accuracy: 0.5488 - val_loss: 0.6884 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5531 - loss: 0.6881\n",
      "Epoch 13: val_accuracy did not improve from 0.55037\n",
      "\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 1s/step - accuracy: 0.5531 - loss: 0.6881 - val_accuracy: 0.5488 - val_loss: 0.6884 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m  1/195\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:55\u001b[0m 1s/step - accuracy: 0.5938 - loss: 0.6822\n",
      "Epoch 14: val_accuracy did not improve from 0.55037\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 109ms/step - accuracy: 0.5938 - loss: 0.6822 - val_accuracy: 0.5488 - val_loss: 0.6884 - learning_rate: 2.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5497 - loss: 0.6884\n",
      "Epoch 15: val_accuracy did not improve from 0.55037\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 1s/step - accuracy: 0.5497 - loss: 0.6884 - val_accuracy: 0.5488 - val_loss: 0.6884 - learning_rate: 2.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m  1/195\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:41\u001b[0m 1s/step - accuracy: 0.5312 - loss: 0.6927\n",
      "Epoch 16: val_accuracy did not improve from 0.55037\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 105ms/step - accuracy: 0.5312 - loss: 0.6927 - val_accuracy: 0.5488 - val_loss: 0.6884 - learning_rate: 2.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5594 - loss: 0.6864\n",
      "Epoch 17: val_accuracy did not improve from 0.55037\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 1s/step - accuracy: 0.5594 - loss: 0.6864 - val_accuracy: 0.5484 - val_loss: 0.6884 - learning_rate: 2.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m  1/195\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:44\u001b[0m 1s/step - accuracy: 0.6250 - loss: 0.6751\n",
      "Epoch 18: val_accuracy did not improve from 0.55037\n",
      "\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 105ms/step - accuracy: 0.6250 - loss: 0.6751 - val_accuracy: 0.5484 - val_loss: 0.6884 - learning_rate: 2.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5411 - loss: 0.6901\n",
      "Epoch 19: val_accuracy did not improve from 0.55037\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 1s/step - accuracy: 0.5411 - loss: 0.6901 - val_accuracy: 0.5484 - val_loss: 0.6884 - learning_rate: 4.0000e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m  1/195\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:58\u001b[0m 1s/step - accuracy: 0.6562 - loss: 0.6667\n",
      "Epoch 20: val_accuracy did not improve from 0.55037\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 109ms/step - accuracy: 0.6562 - loss: 0.6667 - val_accuracy: 0.5484 - val_loss: 0.6884 - learning_rate: 4.0000e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5505 - loss: 0.6883\n",
      "Epoch 21: val_accuracy did not improve from 0.55037\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 1s/step - accuracy: 0.5505 - loss: 0.6883 - val_accuracy: 0.5484 - val_loss: 0.6884 - learning_rate: 4.0000e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m  1/195\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:51\u001b[0m 1s/step - accuracy: 0.6562 - loss: 0.6667\n",
      "Epoch 22: val_accuracy did not improve from 0.55037\n",
      "\u001b[1m195/195\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 107ms/step - accuracy: 0.6562 - loss: 0.6667 - val_accuracy: 0.5484 - val_loss: 0.6884 - learning_rate: 4.0000e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m107/195\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1:54\u001b[0m 1s/step - accuracy: 0.5528 - loss: 0.6876"
     ]
    }
   ],
   "source": [
    "# CHANGE THIS VALUE TO TRAIN DIFFERENT FOLDS (0, 1, 2, 3, 4)\n",
    "CURRENT_FOLD = 0  # Change this to 0, 1, 2, 3, or 4 for each fold\n",
    "\n",
    "def train_single_fold(fold_number, X, y, skf, epochs=50):\n",
    "    \"\"\"Train a single fold\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"TRAINING FOLD {fold_number + 1}/{N_SPLITS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Get the specific fold split\n",
    "    folds = list(skf.split(X, y))\n",
    "    train_idx, val_idx = folds[fold_number]\n",
    "    \n",
    "    # Split data for current fold\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    print(f\"Training samples: {len(X_train)} (Schizo: {np.sum(y_train)}, Healthy: {len(y_train) - np.sum(y_train)})\")\n",
    "    print(f\"Validation samples: {len(X_val)} (Schizo: {np.sum(y_val)}, Healthy: {len(y_val) - np.sum(y_val)})\")\n",
    "    \n",
    "    # Create model for this fold\n",
    "    model = create_cnn_model(IMG_SIZE)\n",
    "    \n",
    "    # Callbacks\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        f'results/fold_{fold_number+1}_model.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    callbacks = [checkpoint, early_stopping, reduce_lr]\n",
    "    \n",
    "    # Data augmentation for training\n",
    "    datagen = create_data_augmentation()\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"Starting training for fold {fold_number + 1}...\")\n",
    "    history = model.fit(\n",
    "        datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "        steps_per_epoch=len(X_train) // BATCH_SIZE,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Load best model for this fold\n",
    "    best_fold_model = load_model(f'results/fold_{fold_number+1}_model.h5')\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_predictions = best_fold_model.predict(X_val)\n",
    "    val_predictions_binary = (val_predictions > 0.5).astype(int).flatten()\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    fold_accuracy = accuracy_score(y_val, val_predictions_binary)\n",
    "    \n",
    "    print(f\"\\nFold {fold_number + 1} Validation Accuracy: {fold_accuracy:.4f}\")\n",
    "    \n",
    "    # Generate confusion matrix for this fold\n",
    "    cm = confusion_matrix(y_val, val_predictions_binary)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "               xticklabels=['Healthy', 'Schizophrenia'],\n",
    "               yticklabels=['Healthy', 'Schizophrenia'])\n",
    "    plt.title(f'Confusion Matrix - Fold {fold_number + 1}\\nAccuracy: {fold_accuracy:.4f}')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'results/confusion_matrix_fold_{fold_number+1}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Classification report\n",
    "    print(f\"\\nClassification Report - Fold {fold_number + 1}:\")\n",
    "    print(classification_report(y_val, val_predictions_binary, \n",
    "                              target_names=['Healthy', 'Schizophrenia']))\n",
    "    \n",
    "    return fold_accuracy, cm, history.history, best_fold_model\n",
    "\n",
    "# Train the current fold\n",
    "fold_accuracy, confusion_mat, history, trained_model = train_single_fold(\n",
    "    CURRENT_FOLD, X, y, skf, EPOCHS\n",
    ")\n",
    "\n",
    "# Store results\n",
    "fold_results.append({\n",
    "    'fold': CURRENT_FOLD + 1,\n",
    "    'accuracy': fold_accuracy,\n",
    "    'confusion_matrix': confusion_mat,\n",
    "    'history': history\n",
    "})\n",
    "\n",
    "fold_accuracies.append(fold_accuracy)\n",
    "\n",
    "# Check if this is the best model so far\n",
    "if fold_accuracy > best_accuracy:\n",
    "    best_accuracy = fold_accuracy\n",
    "    trained_model.save(best_model_path)\n",
    "    print(f\"New best model saved with accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "print(f\"Fold {CURRENT_FOLD + 1} training complete!\")\n",
    "print(f\"To train the next fold, change CURRENT_FOLD to {CURRENT_FOLD + 1} and run this section again.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
