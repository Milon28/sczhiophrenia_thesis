{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62157155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        \n",
    "        # Register hooks\n",
    "        self.target_layer.register_forward_hook(self.save_activation)\n",
    "        self.target_layer.register_backward_hook(self.save_gradient)\n",
    "    \n",
    "    def save_activation(self, module, input, output):\n",
    "        self.activations = output\n",
    "    \n",
    "    def save_gradient(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0]\n",
    "    \n",
    "    def generate_cam(self, input_image, class_idx=None):\n",
    "        # Forward pass\n",
    "        model_output = self.model(input_image)\n",
    "        \n",
    "        if class_idx is None:\n",
    "            class_idx = torch.argmax(model_output, dim=1)\n",
    "        \n",
    "        # Zero gradients\n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        # Backward pass\n",
    "        class_score = model_output[:, class_idx]\n",
    "        class_score.backward()\n",
    "        \n",
    "        # Get gradients and activations\n",
    "        gradients = self.gradients[0]  # Remove batch dimension\n",
    "        activations = self.activations[0]  # Remove batch dimension\n",
    "        \n",
    "        # Calculate weights (global average pooling of gradients)\n",
    "        weights = torch.mean(gradients, dim=(1, 2))\n",
    "        \n",
    "        # Generate CAM\n",
    "        cam = torch.zeros(activations.shape[1:], dtype=torch.float32)\n",
    "        for i, w in enumerate(weights):\n",
    "            cam += w * activations[i, :, :]\n",
    "        \n",
    "        # Apply ReLU to focus on positive contributions\n",
    "        cam = F.relu(cam)\n",
    "        \n",
    "        # Normalize CAM\n",
    "        cam = cam - torch.min(cam)\n",
    "        cam = cam / torch.max(cam)\n",
    "        \n",
    "        return cam.detach().cpu().numpy()\n",
    "\n",
    "def preprocess_image(image_path, size=(224, 224)):\n",
    "    \"\"\"Preprocess image for model input\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    original_image = np.array(image)\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "    \n",
    "    return input_tensor, original_image\n",
    "\n",
    "def overlay_heatmap(image, heatmap, alpha=0.6):\n",
    "    \"\"\"Overlay heatmap on original image\"\"\"\n",
    "    # Resize heatmap to match image size\n",
    "    heatmap_resized = cv2.resize(heatmap, (image.shape[1], image.shape[0]))\n",
    "    \n",
    "    # Convert heatmap to color (using jet colormap)\n",
    "    heatmap_colored = cv2.applyColorMap(np.uint8(255 * heatmap_resized), cv2.COLORMAP_JET)\n",
    "    heatmap_colored = cv2.cvtColor(heatmap_colored, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Overlay\n",
    "    superimposed = heatmap_colored * alpha + image * (1 - alpha)\n",
    "    return superimposed.astype(np.uint8)\n",
    "\n",
    "# Example usage with pretrained ResNet\n",
    "def demo_gradcam():\n",
    "    # Load pretrained model\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.eval()\n",
    "    \n",
    "    # Choose target layer (usually the last convolutional layer)\n",
    "    target_layer = model.layer4[-1].conv3  # For ResNet50\n",
    "    \n",
    "    # Initialize GradCAM\n",
    "    gradcam = GradCAM(model, target_layer)\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    # Replace 'your_image.jpg' with actual image path\n",
    "    image_path = 'your_image.jpg'  \n",
    "    try:\n",
    "        input_tensor, original_image = preprocess_image(image_path)\n",
    "        \n",
    "        # Generate GradCAM\n",
    "        cam = gradcam.generate_cam(input_tensor)\n",
    "        \n",
    "        # Create overlay\n",
    "        overlay = overlay_heatmap(original_image, cam)\n",
    "        \n",
    "        # Visualize results\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        axes[0].imshow(original_image)\n",
    "        axes[0].set_title('Original Image')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        axes[1].imshow(cam, cmap='jet')\n",
    "        axes[1].set_title('GradCAM Heatmap')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        axes[2].imshow(overlay)\n",
    "        axes[2].set_title('Overlay')\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print prediction\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            pred_class = torch.argmax(output, dim=1).item()\n",
    "            confidence = torch.softmax(output, dim=1)[0, pred_class].item()\n",
    "            print(f\"Predicted class: {pred_class}, Confidence: {confidence:.3f}\")\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(\"Image file not found. Please provide a valid image path.\")\n",
    "        print(\"This is a demo code - replace 'your_image.jpg' with actual image path\")\n",
    "\n",
    "# Advanced GradCAM with multiple layers\n",
    "class MultiLayerGradCAM:\n",
    "    def __init__(self, model, target_layers):\n",
    "        self.model = model\n",
    "        self.target_layers = target_layers\n",
    "        self.gradcams = []\n",
    "        \n",
    "        for layer in target_layers:\n",
    "            self.gradcams.append(GradCAM(model, layer))\n",
    "    \n",
    "    def generate_multi_cam(self, input_image, class_idx=None):\n",
    "        cams = []\n",
    "        for gradcam in self.gradcams:\n",
    "            cam = gradcam.generate_cam(input_image, class_idx)\n",
    "            cams.append(cam)\n",
    "        return cams\n",
    "\n",
    "# Common issues and solutions:\n",
    "\n",
    "def troubleshoot_gradcam():\n",
    "    \"\"\"\n",
    "    Common GradCAM issues and solutions:\n",
    "    \n",
    "    1. Gradient is None:\n",
    "       - Make sure model is in eval() mode but still allows gradients\n",
    "       - Check if target layer is correct\n",
    "       - Ensure backward() is called on the correct tensor\n",
    "    \n",
    "    2. CAM shows random patterns:\n",
    "       - Wrong target layer selected\n",
    "       - Model not properly pretrained\n",
    "       - Input preprocessing mismatch\n",
    "    \n",
    "    3. CAM too bright/dark:\n",
    "       - Adjust normalization\n",
    "       - Check alpha value in overlay\n",
    "       - Verify image preprocessing\n",
    "    \n",
    "    4. CAM doesn't highlight expected regions:\n",
    "       - Model might be using different features than expected\n",
    "       - Try different target layers\n",
    "       - Check if model is actually confident in prediction\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "# For custom models, modify target layer selection:\n",
    "def get_target_layer_examples():\n",
    "    \"\"\"\n",
    "    Examples of target layer selection for different architectures:\n",
    "    \n",
    "    ResNet: model.layer4[-1].conv3\n",
    "    VGG: model.features[-1]\n",
    "    DenseNet: model.features[-1]\n",
    "    EfficientNet: model.features[-1]\n",
    "    \n",
    "    For custom models, choose the last convolutional layer before\n",
    "    global average pooling or fully connected layers.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo_gradcam()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
