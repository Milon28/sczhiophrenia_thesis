{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2e6bc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "#if using Theano with GPU\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib.pyplot import imshow\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44322e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#root = '101_ObjectCategories'\n",
    "#exclude = ['BACKGROUND_Google', 'Motorbikes', 'airplanes', 'Faces_easy', 'Faces']\n",
    "root = 'D:/Milon2/final_CNN/Chunk_average_spectro'\n",
    "train_split, val_split = 0.7, 0.15\n",
    "\n",
    "categories = [x[0] for x in os.walk(root) if x[0]][1:]\n",
    "#categories = [c for c in categories if c not in [os.path.join(root, e) for e in exclude]]\n",
    "\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc67997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to load image and return it and input vector\n",
    "def get_image(path):\n",
    "    img = image.load_img(path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return img, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7efbd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for c, category in enumerate(categories):\n",
    "    images = [os.path.join(dp, f) for dp, dn, filenames \n",
    "              in os.walk(category) for f in filenames \n",
    "              if os.path.splitext(f)[1].lower() in ['.jpg','.png','.jpeg']]\n",
    "    for img_path in images:\n",
    "        img, x = get_image(img_path)\n",
    "        data.append({'x':np.array(x[0]), 'y':c})\n",
    "\n",
    "# count the number of classes\n",
    "num_classes = len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951db015",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "fold_no = 1\n",
    "\n",
    "for train, test in kfold.split(data):\n",
    "    # Create output file paths using f-strings\n",
    "    train_path = f\"D:/Milon2/final_CNN/result/data/train/train{fold_no}.csv\"\n",
    "    test_path = f\"D:/Milon2/final_CNN/result/data/test/test{fold_no}.csv\"\n",
    "\n",
    "    # Save if not already present\n",
    "    if not os.path.exists(train_path):\n",
    "        np.savetxt(train_path, train, delimiter=\",\", fmt='%s')\n",
    "        np.savetxt(test_path, test, delimiter=\",\", fmt='%s')\n",
    "    else:\n",
    "        print(\"exists\")\n",
    "\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aff9b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = np.array([t[\"x\"] for t in data]), np.array([t[\"y\"] for t in data])\n",
    "\n",
    "# normalize data\n",
    "X = X.astype('float32') / 255.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728be0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define per-fold score containers <-- these are new\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras import utils as np_utils\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for fold_no in range(1, 6):\n",
    "    \n",
    "    train=pd.read_csv(f\"D:/Milon2/final_CNN/result/data/train/train{fold_no}.csv\", sep=',',header=None)\n",
    "    test=pd.read_csv(f\"D:/Milon2/final_CNN/result/data/test/test{fold_no}.csv\", sep=',',header=None)\n",
    "    \n",
    "    x_train = X[train[0]]\n",
    "    y_train = y[train[0]]\n",
    "    x_test = X[test[0]]\n",
    "    y_test = y[test[0]]\n",
    "\n",
    "    # x_train, y_train = np.array([t[\"x\"] for t in train]), [t[\"y\"] for t in train]\n",
    "    # x_test, y_test = np.array([t[\"x\"] for t in test]), [t[\"y\"] for t in test]\n",
    "\n",
    "    # normalize data\n",
    "    # x_train = x_train.astype('float32') / 255.\n",
    "    # x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "    # convert labels to one-hot vectors\n",
    "    y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "    y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "    print(y_test.shape)\n",
    "\n",
    "    # summary\n",
    "    print(\"finished loading %d images from %d categories\"%(len(data), num_classes))\n",
    "    print(\"train / test split: %d, %d\"%(len(x_train), len(x_test)))\n",
    "    print(\"training data shape: \", x_train.shape)\n",
    "    print(\"training labels shape: \", y_train.shape)\n",
    "\n",
    "    #x_train = X[train]\n",
    "    #y_train = y[train]\n",
    "    #x_test = X[test]\n",
    "    #y_test = y[test]\n",
    "    \n",
    "    \n",
    "    # build the network\n",
    "    model = Sequential()\n",
    "    #print(\"Input dimensions: \",x_train.shape[1:])\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    #filepath=\"C:/Users/s4629860/Documents/Workspace/SZ/Dataset 5/CNN_epochs:{epoch:03d}-val_acc:{val_acc:.3f}.hdf5\"\n",
    "    filepath=f\"D:/Milon2/final_CNN/result/model/best_model{fold_no}.best.keras\"\n",
    "    \n",
    "    # define early stopping callback\n",
    "    earlystop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=150, mode='auto')\n",
    "\n",
    "    # saves the model weights after each epoch if the validation loss decreased\n",
    "    #checkpointer = ModelCheckpoint(filepath='LSTM_model.best.hdf5', verbose=1, save_best_only=True)\n",
    "    checkpointer = ModelCheckpoint(filepath=filepath, verbose=1, save_best_only=True, monitor='val_accuracy')\n",
    "\n",
    "    callbacks_list = [earlystop, checkpointer]\n",
    "    \n",
    "    history = model.fit(x_train, y_train, epochs = 5, batch_size=32,validation_data= (x_test, y_test), callbacks = callbacks_list)\n",
    "\n",
    "    #load saved best model\n",
    "    model = load_model(filepath)\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    Y_pred = model.predict(x_test)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    y_text_new = np.argmax(y_test, axis=1)\n",
    "\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    #Confution Matrix and Classification Report\n",
    "\n",
    "    print('Confusion Matrix')\n",
    "    confusion = confusion_matrix(y_text_new, y_pred)\n",
    "    print(confusion)\n",
    "    print('Classification Report')\n",
    "    target_names = ['AD', 'Normal']\n",
    "    print(classification_report(y_text_new, y_pred, target_names=target_names))\n",
    "\n",
    "    fig = plt.figure(figsize=(16,4))\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax.plot(history.history[\"val_loss\"])\n",
    "    ax.set_title(\"validation loss\")\n",
    "    ax.set_xlabel(\"epochs\")\n",
    "\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.plot(history.history[\"val_accuracy\"])\n",
    "    ax2.set_title(\"validation accuracy\")\n",
    "    ax2.set_xlabel(\"epochs\")\n",
    "    ax2.set_ylim(0, 1)\n",
    "\n",
    "    # Increase fold number\n",
    "    #fold_no = fold_no + 1\n",
    "    plt.show()\n",
    "    \n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(confusion, annot=True, fmt=\"d\", ax = ax); #annot=True to annotate cells\n",
    "\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "    ax.set_title('Confusion Matrix'); \n",
    "    ax.xaxis.set_ticklabels(['ScZ', 'Healthy']); ax.yaxis.set_ticklabels(['ScZ', 'Healthy']);\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa43a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
