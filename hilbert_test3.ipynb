{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54a18c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "import cv2\n",
    "from collections import Counter\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c28996a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Loaded 9381 images\n",
      "Schizophrenia samples: 5146\n",
      "Healthy samples: 4235\n",
      "Image shape: (9381, 224, 224, 3)\n",
      "\n",
      "Starting 5-fold cross validation...\n",
      "\n",
      "==================================================\n",
      "FOLD 1/5\n",
      "==================================================\n",
      "Training samples: 7504 (Schizo: 4116, Healthy: 3388)\n",
      "Validation samples: 1877 (Schizo: 1030, Healthy: 847)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\code\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "d:\\code\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m100/234\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m5:26\u001b[0m 2s/step - accuracy: 0.5083 - loss: 6.5250"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "class EEGCNNClassifier:\n",
    "    def __init__(self, schizophrenia_path, healthy_path, img_size=(224, 224)):\n",
    "        self.schizophrenia_path = schizophrenia_path\n",
    "        self.healthy_path = healthy_path\n",
    "        self.img_size = img_size\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        self.fold_results = []\n",
    "        \n",
    "    def load_and_preprocess_data(self):\n",
    "        \"\"\"Load and preprocess HHT plot images\"\"\"\n",
    "        print(\"Loading and preprocessing data...\")\n",
    "        \n",
    "        # Load schizophrenia images (label: 1)\n",
    "        schizo_files = glob.glob(os.path.join(self.schizophrenia_path, \"*.png\"))\n",
    "        for file_path in schizo_files:\n",
    "            try:\n",
    "                img = load_img(file_path, target_size=self.img_size)\n",
    "                img_array = img_to_array(img) / 255.0  # Normalize to [0,1]\n",
    "                self.X.append(img_array)\n",
    "                self.y.append(1)  # Schizophrenia\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file_path}: {e}\")\n",
    "        \n",
    "        # Load healthy images (label: 0)\n",
    "        healthy_files = glob.glob(os.path.join(self.healthy_path, \"*.png\"))\n",
    "        for file_path in healthy_files:\n",
    "            try:\n",
    "                img = load_img(file_path, target_size=self.img_size)\n",
    "                img_array = img_to_array(img) / 255.0  # Normalize to [0,1]\n",
    "                self.X.append(img_array)\n",
    "                self.y.append(0)  # Healthy\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file_path}: {e}\")\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        self.X = np.array(self.X)\n",
    "        self.y = np.array(self.y)\n",
    "        \n",
    "        print(f\"Loaded {len(self.X)} images\")\n",
    "        print(f\"Schizophrenia samples: {np.sum(self.y == 1)}\")\n",
    "        print(f\"Healthy samples: {np.sum(self.y == 0)}\")\n",
    "        print(f\"Image shape: {self.X.shape}\")\n",
    "        \n",
    "    def create_cnn_model(self):\n",
    "        \"\"\"Create CNN architecture for EEG classification\"\"\"\n",
    "        model = Sequential([\n",
    "            # First Conv Block\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=(*self.img_size, 3)),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D(2, 2),\n",
    "            \n",
    "            # Second Conv Block\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D(2, 2),\n",
    "            \n",
    "            # Third Conv Block\n",
    "            Conv2D(128, (3, 3), activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D(2, 2),\n",
    "            \n",
    "            # Fourth Conv Block\n",
    "            Conv2D(256, (3, 3), activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D(2, 2),\n",
    "            \n",
    "            # Flatten and Dense layers\n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(256, activation='relu'),\n",
    "            Dropout(0.3),\n",
    "            Dense(1, activation='sigmoid')  # Binary classification\n",
    "        ])\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def create_data_augmentation(self):\n",
    "        \"\"\"Create data augmentation generator\"\"\"\n",
    "        return ImageDataGenerator(\n",
    "            rotation_range=10,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            horizontal_flip=True,\n",
    "            zoom_range=0.1,\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "    \n",
    "    def train_with_cross_validation(self, n_splits=5, epochs=50):\n",
    "        \"\"\"Train model with 5-fold cross validation\"\"\"\n",
    "        print(f\"\\nStarting {n_splits}-fold cross validation...\")\n",
    "        \n",
    "        # Initialize StratifiedKFold\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        \n",
    "        fold_accuracies = []\n",
    "        best_accuracy = 0\n",
    "        best_model_path = \"best_eeg_cnn_model.h5\"\n",
    "        \n",
    "        # Create results directory\n",
    "        os.makedirs(\"results\", exist_ok=True)\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(self.X, self.y)):\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"FOLD {fold + 1}/{n_splits}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            # Split data for current fold\n",
    "            X_train, X_val = self.X[train_idx], self.X[val_idx]\n",
    "            y_train, y_val = self.y[train_idx], self.y[val_idx]\n",
    "            \n",
    "            print(f\"Training samples: {len(X_train)} (Schizo: {np.sum(y_train)}, Healthy: {len(y_train) - np.sum(y_train)})\")\n",
    "            print(f\"Validation samples: {len(X_val)} (Schizo: {np.sum(y_val)}, Healthy: {len(y_val) - np.sum(y_val)})\")\n",
    "            \n",
    "            # Create model for this fold\n",
    "            model = self.create_cnn_model()\n",
    "            \n",
    "            # Callbacks\n",
    "            checkpoint = ModelCheckpoint(\n",
    "                f'results/fold_{fold+1}_model.h5',\n",
    "                monitor='val_accuracy',\n",
    "                save_best_only=True,\n",
    "                mode='max',\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            early_stopping = EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=10,\n",
    "                restore_best_weights=True,\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            reduce_lr = ReduceLROnPlateau(\n",
    "                monitor='val_loss',\n",
    "                factor=0.2,\n",
    "                patience=5,\n",
    "                min_lr=1e-7,\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            callbacks = [checkpoint, early_stopping, reduce_lr]\n",
    "            \n",
    "            # Data augmentation for training\n",
    "            datagen = self.create_data_augmentation()\n",
    "            \n",
    "            # Train model\n",
    "            history = model.fit(\n",
    "                datagen.flow(X_train, y_train, batch_size=32),\n",
    "                steps_per_epoch=len(X_train) // 32,\n",
    "                epochs=epochs,\n",
    "                validation_data=(X_val, y_val),\n",
    "                callbacks=callbacks,\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            # Load best model for this fold\n",
    "            best_fold_model = load_model(f'results/fold_{fold+1}_model.h5')\n",
    "            \n",
    "            # Evaluate on validation set\n",
    "            val_predictions = best_fold_model.predict(X_val)\n",
    "            val_predictions_binary = (val_predictions > 0.5).astype(int).flatten()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            fold_accuracy = accuracy_score(y_val, val_predictions_binary)\n",
    "            fold_accuracies.append(fold_accuracy)\n",
    "            \n",
    "            print(f\"\\nFold {fold + 1} Validation Accuracy: {fold_accuracy:.4f}\")\n",
    "            \n",
    "            # Save best overall model\n",
    "            if fold_accuracy > best_accuracy:\n",
    "                best_accuracy = fold_accuracy\n",
    "                best_fold_model.save(best_model_path)\n",
    "                print(f\"New best model saved with accuracy: {best_accuracy:.4f}\")\n",
    "            \n",
    "            # Generate confusion matrix for this fold\n",
    "            cm = confusion_matrix(y_val, val_predictions_binary)\n",
    "            \n",
    "            # Plot confusion matrix\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                       xticklabels=['Healthy', 'Schizophrenia'],\n",
    "                       yticklabels=['Healthy', 'Schizophrenia'])\n",
    "            plt.title(f'Confusion Matrix - Fold {fold + 1}\\nAccuracy: {fold_accuracy:.4f}')\n",
    "            plt.ylabel('True Label')\n",
    "            plt.xlabel('Predicted Label')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'results/confusion_matrix_fold_{fold+1}.png', dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "            # Classification report\n",
    "            print(f\"\\nClassification Report - Fold {fold + 1}:\")\n",
    "            print(classification_report(y_val, val_predictions_binary, \n",
    "                                      target_names=['Healthy', 'Schizophrenia']))\n",
    "            \n",
    "            # Store fold results\n",
    "            self.fold_results.append({\n",
    "                'fold': fold + 1,\n",
    "                'accuracy': fold_accuracy,\n",
    "                'confusion_matrix': cm,\n",
    "                'history': history.history\n",
    "            })\n",
    "        \n",
    "        # Calculate overall statistics\n",
    "        mean_accuracy = np.mean(fold_accuracies)\n",
    "        std_accuracy = np.std(fold_accuracies)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"CROSS VALIDATION RESULTS\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Individual fold accuracies: {[f'{acc:.4f}' for acc in fold_accuracies]}\")\n",
    "        print(f\"Mean Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "        print(f\"Best Accuracy: {best_accuracy:.4f}\")\n",
    "        print(f\"Best model saved as: {best_model_path}\")\n",
    "        \n",
    "        return mean_accuracy, std_accuracy, best_accuracy\n",
    "    \n",
    "    def plot_training_history(self):\n",
    "        \"\"\"Plot training history for all folds\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        for i, result in enumerate(self.fold_results):\n",
    "            history = result['history']\n",
    "            fold = result['fold']\n",
    "            \n",
    "            # Plot accuracy\n",
    "            axes[0, 0].plot(history['accuracy'], label=f'Fold {fold} Train')\n",
    "            axes[0, 1].plot(history['val_accuracy'], label=f'Fold {fold} Val')\n",
    "            \n",
    "            # Plot loss\n",
    "            axes[1, 0].plot(history['loss'], label=f'Fold {fold} Train')\n",
    "            axes[1, 1].plot(history['val_loss'], label=f'Fold {fold} Val')\n",
    "        \n",
    "        axes[0, 0].set_title('Training Accuracy')\n",
    "        axes[0, 0].set_xlabel('Epoch')\n",
    "        axes[0, 0].set_ylabel('Accuracy')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True)\n",
    "        \n",
    "        axes[0, 1].set_title('Validation Accuracy')\n",
    "        axes[0, 1].set_xlabel('Epoch')\n",
    "        axes[0, 1].set_ylabel('Accuracy')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True)\n",
    "        \n",
    "        axes[1, 0].set_title('Training Loss')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Loss')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True)\n",
    "        \n",
    "        axes[1, 1].set_title('Validation Loss')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Loss')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/training_history.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Update these paths to your actual data directories\n",
    "    SCHIZOPHRENIA_PATH = \"D:/HHT/S\"  # Replace with your path\n",
    "    HEALTHY_PATH = \"D:/HHT/H\"  # Replace with your path\n",
    "    \n",
    "    # Initialize classifier\n",
    "    classifier = EEGCNNClassifier(\n",
    "        schizophrenia_path=SCHIZOPHRENIA_PATH,\n",
    "        healthy_path=HEALTHY_PATH,\n",
    "        img_size=(224, 224)  # Adjust based on your image size\n",
    "    )\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    classifier.load_and_preprocess_data()\n",
    "    \n",
    "    # Train with 5-fold cross validation\n",
    "    mean_acc, std_acc, best_acc = classifier.train_with_cross_validation(\n",
    "        n_splits=5, \n",
    "        epochs=50\n",
    "    )\n",
    "    \n",
    "    # Plot training history\n",
    "    classifier.plot_training_history()\n",
    "    \n",
    "    print(f\"\\nFinal Results:\")\n",
    "    print(f\"Mean CV Accuracy: {mean_acc:.4f} ± {std_acc:.4f}\")\n",
    "    print(f\"Best Model Accuracy: {best_acc:.4f}\")\n",
    "    print(f\"Best model saved as: best_eeg_cnn_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
